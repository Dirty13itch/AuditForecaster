# Query Performance Analysis Report

**Date**: October 24, 2025  
**Phase**: Database Index Optimization - Phase 2  
**Status**: ‚ö†Ô∏è **CRITICAL FINDINGS - IMMEDIATE ACTION REQUIRED**

## Executive Summary

Analysis reveals **critical performance issues** in dashboard and leaderboard queries. Current implementation uses **client-side aggregation** (JavaScript forEach/reduce) instead of SQL aggregation, which will fail at production scale. Two queries fetch entire datasets into memory and perform complex calculations in-app.

## Critical Findings

### üî¥ **Query 1 & 2: Client-Side Aggregation Anti-Pattern**

**Current Implementation**:
```typescript
// getDashboardSummary() - Lines 1299-1427
const completedJobs = await db.select()
  .from(jobs)
  .innerJoin(forecasts, eq(jobs.id, forecasts.jobId))
  .where(eq(jobs.status, 'completed'));

// Fetches ALL completed jobs into memory (could be 10K+ rows)
// Then does JavaScript aggregation:
const totalACH50 = jobsWithACH50.reduce((sum, job) => sum + job.ach50, 0);
const averageACH50 = totalACH50 / totalInspections;
jobsWithACH50.forEach(job => {
  const tier = calculateTier(job.ach50);
  tierCounts[tier]++;
  // More calculations...
});
```

**Performance Impact at Scale**:
- **10K jobs**: ~5MB memory, 500-1000ms processing
- **50K jobs**: ~25MB memory, 2000-5000ms processing
- **100K jobs**: ~50MB memory, 5000-10000ms processing + risk of OOM

**Root Cause**: Fetching entire result set instead of using SQL `GROUP BY`, `COUNT()`, `AVG()`, `SUM()`

---

### üî¥ **Query 2: Builder Leaderboard - Nested Loop Aggregation**

**Current Implementation**:
```typescript
// getBuilderLeaderboard() - Lines 1430-1526
const allBuilders = await db.select().from(builders); // Fetch ALL builders
const completedJobs = await db.select()              // Fetch ALL completed jobs
  .from(jobs)
  .innerJoin(forecasts, eq(jobs.id, forecasts.jobId))
  .where(eq(jobs.status, 'completed'));

// Nested loop: O(builders √ó jobs) complexity
const leaderboard = allBuilders.map(builder => {
  const builderJobs = completedJobs.filter(row => row.jobs.builderId === builder.id);
  // Calculate averageACH50, tier, pass rate for each builder
  // Sort, count, reduce operations per builder
});
```

**Performance Impact**:
- **100 builders √ó 10K jobs**: ~1 second (100K filter operations)
- **200 builders √ó 50K jobs**: ~10 seconds (10M filter operations)
- **500 builders √ó 100K jobs**: ~60+ seconds (50M filter operations)

**Root Cause**: Cartesian product in memory instead of SQL `GROUP BY builders.id`

---

## Query Analysis Results (Actual Implementation)

### Query 1: Dashboard Summary

**Actual SQL Generated by Drizzle**:
```sql
SELECT jobs.*, forecasts.*
FROM jobs
INNER JOIN forecasts ON jobs.id = forecasts.job_id
WHERE jobs.status = 'completed';
-- No LIMIT, no aggregation, no GROUP BY
```

**EXPLAIN ANALYZE**:
```
Nested Loop  (cost=0.00..1.14 rows=1 width=566) (actual time=0.703ms rows=0)
  ->  Seq Scan on jobs  (Filter: status = 'completed') (rows=0)
  ->  Seq Scan on forecasts (never executed)
```

**Current Dataset**: 0 completed jobs  
**Index Utilization**: None (would use `idx_jobs_status_scheduled_date` but irrelevant)  
**Critical Issue**: ‚ùå **Fetches all rows then aggregates in JavaScript**

**Correct Implementation** (SQL aggregation):
```sql
-- This is what the query SHOULD be:
SELECT 
  COUNT(*) as total_inspections,
  AVG(forecasts.actual_ach50) as average_ach50,
  SUM(CASE WHEN forecasts.actual_ach50 <= 3.0 THEN 1 ELSE 0 END) as pass_count,
  SUM(CASE WHEN forecasts.actual_ach50 > 3.0 THEN 1 ELSE 0 END) as fail_count,
  SUM(CASE WHEN forecasts.actual_ach50 <= 1.0 THEN 1 ELSE 0 END) as elite_count,
  -- More aggregations...
FROM jobs
INNER JOIN forecasts ON jobs.id = forecasts.job_id
WHERE jobs.status = 'completed'
  AND forecasts.actual_ach50 IS NOT NULL;
```

**Estimated Performance**:
- Current (10K jobs): ~800ms (fetch 10K rows + JS aggregation)
- Optimized SQL (10K jobs): **~15ms** (single aggregation query)
- **Improvement**: **98% faster** (53x speedup)

---

### Query 2: Builder Leaderboard

**Actual SQL Generated**:
```sql
-- Query 1: Fetch all builders
SELECT * FROM builders;

-- Query 2: Fetch all completed jobs
SELECT jobs.*, forecasts.*
FROM jobs
INNER JOIN forecasts ON jobs.id = forecasts.job_id
WHERE jobs.status = 'completed';

-- Then JavaScript nested loop over both result sets
```

**EXPLAIN ANALYZE** (Query 2 only):
```
Nested Loop (cost=0.00..1.14 rows=1 width=566) (actual time=0.042ms rows=0)
  ->  Seq Scan on jobs (Filter: status = 'completed') (rows=0)
  ->  Seq Scan on forecasts (never executed)
```

**Current Dataset**: 0 completed jobs, 0 builders  
**Critical Issue**: ‚ùå **O(N√óM) nested loop in JavaScript**

**Correct Implementation** (SQL GROUP BY):
```sql
SELECT 
  builders.id,
  builders.name,
  builders.company_name,
  COUNT(*) as total_jobs,
  AVG(forecasts.actual_ach50) as average_ach50,
  MIN(forecasts.actual_ach50) as best_ach50,
  MAX(jobs.completed_date) as latest_completed,
  SUM(CASE WHEN forecasts.actual_ach50 <= 3.0 THEN 1 ELSE 0 END) as pass_count,
  SUM(CASE WHEN forecasts.actual_ach50 <= 1.0 THEN 1 ELSE 0 END) as elite_count
  -- More aggregations...
FROM builders
LEFT JOIN jobs ON builders.id = jobs.builder_id
LEFT JOIN forecasts ON jobs.id = forecasts.job_id
WHERE jobs.status = 'completed'
  AND forecasts.actual_ach50 IS NOT NULL
GROUP BY builders.id, builders.name, builders.company_name
ORDER BY average_ach50 ASC;
```

**Estimated Performance**:
- Current (200 builders √ó 10K jobs): ~5000ms (nested loop)
- Optimized SQL (200 builders √ó 10K jobs): **~50ms** (single GROUP BY)
- **Improvement**: **99% faster** (100x speedup)

---

### Query 3: Photos Cursor Pagination with RBAC

**SQL Generated by Drizzle**:
```sql
SELECT photos.*
FROM photos
LEFT JOIN jobs ON photos.job_id = jobs.id
WHERE jobs.created_by = $1
  AND photos.uploaded_at < $2
ORDER BY photos.uploaded_at DESC
LIMIT 51;
```

**EXPLAIN ANALYZE**:
```
Limit  (cost=1.15..1.15 rows=1) (actual time=0.055ms rows=0)
  ->  Sort (Sort Key: photos.uploaded_at DESC)
        ->  Nested Loop (Join: jobs.id = photos.job_id)
              ->  Seq Scan on photos (Filter: uploaded_at < now())
              ->  Seq Scan on jobs (Filter: created_by = 'test-user-id')
```

**Status**: ‚úÖ **Correctly implemented** - Cursor pagination, proper filtering  
**Index Ready**: `idx_photos_job_id_uploaded_at`, `idx_jobs_created_by`  
**Production Target**: <150ms for 50K photos

---

### Query 4: Photos Tag Filter (GIN Index)

**SQL Generated**:
```sql
SELECT * FROM photos
WHERE tags @> ARRAY['exterior', 'HVAC']::text[]
ORDER BY uploaded_at DESC
LIMIT 50;
```

**EXPLAIN ANALYZE**:
```
Limit (cost=0.01..0.02 rows=1) (actual time=0.035ms rows=0)
  ->  Sort (Sort Key: uploaded_at DESC)
        ->  Seq Scan on photos (Filter: tags @> '{exterior,HVAC}')
```

**Status**: ‚úÖ **Correctly implemented** - GIN index ready  
**Index Ready**: `idx_photos_tags` (GIN on tags array)  
**Production Target**: <100ms for 50K photos

---

### Query 5: Audit Logs

**SQL Generated**:
```sql
SELECT * FROM audit_logs
WHERE user_id = $1
  AND resource_type = $2
ORDER BY timestamp DESC
LIMIT 50;
```

**EXPLAIN ANALYZE**:
```
Limit (cost=8.17..8.18 rows=1) (actual time=0.050ms rows=0)
  ->  Sort (Sort Key: timestamp DESC)
        ->  Index Scan using idx_audit_logs_resource
              Index Cond: (resource_type = 'job')
              Filter: (user_id = 'test-user-id')
```

**Status**: ‚úÖ **Index already active!** (`idx_audit_logs_resource`)  
**Production Target**: <50ms

---

### Query 6: Jobs RBAC Pagination

**SQL Generated**:
```sql
SELECT * FROM jobs
WHERE status = 'scheduled'
  AND created_by = $1
ORDER BY id DESC
LIMIT 21;
```

**EXPLAIN ANALYZE**:
```
Limit (cost=1.16..1.16 rows=1) (actual time=0.060ms rows=0)
  ->  Sort (Sort Key: id DESC)
        ->  Seq Scan on jobs
              Filter: (status = 'scheduled' AND created_by = 'test-user-id')
```

**Status**: ‚úÖ **Correctly implemented** - Cursor pagination ready  
**Index Ready**: `idx_jobs_status_created_by`  
**Production Target**: <100ms for 10K jobs

---

## Critical Recommendations

### üî¥ **IMMEDIATE: Rewrite Dashboard & Leaderboard Queries**

Both `getDashboardSummary()` and `getBuilderLeaderboard()` must be rewritten to use SQL aggregation.

**Implementation Options**:

#### Option A: Pure SQL Aggregation (Recommended)
- Rewrite storage methods to use Drizzle's `sql` aggregation functions
- Use `COUNT()`, `AVG()`, `SUM()`, `CASE` statements
- **Pros**: Immediate improvement, no infrastructure changes
- **Cons**: Complex SQL, harder to maintain
- **Effort**: 4-8 hours development + testing

#### Option B: Materialized Views (Recommended for production)
- Create `dashboard_summary_mv` and `builder_leaderboard_mv`
- Refresh every 5 minutes or trigger-based on job completion
- **Pros**: Blazing fast (<10ms), simple queries
- **Cons**: Requires view refresh infrastructure
- **Effort**: 6-12 hours development + refresh scheduler

#### Option C: Hybrid Approach (Best long-term)
- Use SQL aggregation for real-time accuracy
- Add materialized views for frequently accessed metrics
- Cache materialized view results (5-minute TTL)
- **Pros**: Best of both worlds
- **Cons**: Most complex
- **Effort**: 8-16 hours

---

## Index Effectiveness Summary

| Query | Implementation | Current | At Scale (10K jobs) | Fix Required |
|-------|---------------|---------|---------------------|--------------|
| Dashboard Summary | ‚ùå JS aggregation | 0.7ms | **800-1000ms** | ‚úÖ SQL rewrite |
| Builder Leaderboard | ‚ùå Nested loop | 0.04ms | **5000-10000ms** | ‚úÖ SQL GROUP BY |
| Photos RBAC Pagination | ‚úÖ Proper SQL | 0.055ms | ~150ms | No |
| Photos Tag Filter | ‚úÖ GIN index | 0.035ms | ~100ms | No |
| Audit Logs | ‚úÖ Index active | 0.050ms | ~50ms | No |
| Jobs RBAC Pagination | ‚úÖ Proper SQL | 0.060ms | ~100ms | No |

**Status**: üî¥ **4/6 queries optimized**, **2/6 require immediate refactoring**

---

## Updated Phase Priorities

### Phase 2.5: Critical Query Refactoring (NEW - URGENT)

**Must complete before production deployment**:

1. **Rewrite `getDashboardSummary()`** (server/storage.ts:1299-1427)
   - Replace JavaScript aggregation with SQL `GROUP BY`
   - Use Drizzle's `sql` template for `COUNT()`, `AVG()`, `SUM(CASE...)`
   - Test with 10K+ jobs to validate <50ms target

2. **Rewrite `getBuilderLeaderboard()`** (server/storage.ts:1430-1526)
   - Replace nested loop with SQL `GROUP BY builders.id`
   - Join builders ‚Üí jobs ‚Üí forecasts, aggregate in SQL
   - Test with 200+ builders, 10K+ jobs to validate <150ms target

3. **Add Integration Tests**
   - Seed database with 10K jobs, 100 builders, 50K photos
   - Measure actual query performance
   - Validate index usage with `EXPLAIN ANALYZE`

**Estimated Effort**: 6-12 hours  
**Priority**: üî¥ **CRITICAL** - Blocks production deployment

---

### Phase 3: Connection Pooling (After 2.5)

Configure Neon client pooling: max 10 connections, timeouts

### Phase 4: Materialized Views (Conditional)

Implement if SQL aggregation still exceeds 150ms target

---

## Conclusion

**Phase 2 Status**: ‚ö†Ô∏è **INCOMPLETE - CRITICAL ISSUES FOUND**

Phase 1 indexes are correctly implemented, but **dashboard and leaderboard queries use anti-patterns** that will cause severe performance degradation at production scale. These queries must be refactored to use SQL aggregation before deployment.

**Immediate Actions**:
1. ‚ùå Cannot mark `phase1-performance-3b` as completed
2. üîÑ Create new task: `phase1-performance-3b-fix` - Refactor dashboard/leaderboard SQL
3. üîÑ After fix, re-run EXPLAIN ANALYZE to validate improvements

**Next Steps**:
1. Refactor `getDashboardSummary()` and `getBuilderLeaderboard()` to use SQL
2. Add load testing with production-scale dataset
3. Re-run Phase 2 analysis with corrected queries
4. Then proceed to Phase 3 (connection pooling)

---

## Appendix: SQL Aggregation Examples

### Dashboard Summary (Corrected)

```sql
WITH job_stats AS (
  SELECT 
    COUNT(*) as total_inspections,
    AVG(forecasts.actual_ach50) as average_ach50,
    SUM(CASE WHEN forecasts.actual_ach50 <= 3.0 THEN 1 ELSE 0 END) as pass_count,
    SUM(CASE WHEN forecasts.actual_ach50 > 3.0 THEN 1 ELSE 0 END) as fail_count,
    SUM(CASE WHEN forecasts.actual_ach50 <= 1.0 THEN 1 ELSE 0 END) as elite_count,
    SUM(CASE WHEN forecasts.actual_ach50 > 1.0 AND forecasts.actual_ach50 <= 1.5 THEN 1 ELSE 0 END) as excellent_count,
    SUM(CASE WHEN forecasts.actual_ach50 > 1.5 AND forecasts.actual_ach50 <= 2.0 THEN 1 ELSE 0 END) as very_good_count,
    SUM(CASE WHEN forecasts.actual_ach50 > 2.0 AND forecasts.actual_ach50 <= 2.5 THEN 1 ELSE 0 END) as good_count,
    SUM(CASE WHEN forecasts.actual_ach50 > 2.5 AND forecasts.actual_ach50 <= 3.0 THEN 1 ELSE 0 END) as passing_count,
    SUM(CASE WHEN forecasts.actual_ach50 > 3.0 THEN 1 ELSE 0 END) as failing_count
  FROM jobs
  INNER JOIN forecasts ON jobs.id = forecasts.job_id
  WHERE jobs.status = 'completed'
    AND forecasts.actual_ach50 IS NOT NULL
)
SELECT * FROM job_stats;
```

### Builder Leaderboard (Corrected)

```sql
SELECT 
  builders.id,
  builders.name,
  builders.company_name,
  COUNT(jobs.id) as total_jobs,
  AVG(forecasts.actual_ach50) as average_ach50,
  MIN(forecasts.actual_ach50) as best_ach50,
  (COUNT(CASE WHEN forecasts.actual_ach50 <= 3.0 THEN 1 END)::float / COUNT(jobs.id) * 100) as pass_rate,
  SUM(CASE WHEN forecasts.actual_ach50 <= 1.0 THEN 1 ELSE 0 END) as elite_count,
  SUM(CASE WHEN forecasts.actual_ach50 > 1.0 AND forecasts.actual_ach50 <= 1.5 THEN 1 ELSE 0 END) as excellent_count,
  MAX(jobs.completed_date) as latest_completed
FROM builders
LEFT JOIN jobs ON builders.id = jobs.builder_id AND jobs.status = 'completed'
LEFT JOIN forecasts ON jobs.id = forecasts.job_id AND forecasts.actual_ach50 IS NOT NULL
GROUP BY builders.id, builders.name, builders.company_name
HAVING COUNT(jobs.id) > 0
ORDER BY average_ach50 ASC
LIMIT 100;
```

**Performance**: Both queries ~15-50ms with proper indexes, regardless of dataset size.
